{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptionFramework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLiCUnFBiU9u",
        "colab_type": "text"
      },
      "source": [
        "# Option Framework\n",
        "\n",
        "**Papers**\n",
        "* [Option Framework](https://www.sciencedirect.com/science/article/pii/S0004370299000521)\n",
        "* [Learning Options in Reinforcement Learning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.2402&rep=rep1&type=pdf)\n",
        "\n",
        "\n",
        "In this notebook I'm exploring the Option Framework while implementing the algorithm proposed at the \"Learning Options in Reinforcement Learning\" paper.\n",
        "The Option Framework tries to address challenges like: learning, planning, and representing knowledge at multiple levels of temporal abstraction. To do that they introduce a new notion of action which they call Option, which is basically an extension of the action as we know. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTLSNhvnBLmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from gym import core, spaces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0mR58AC9x5n",
        "colab_type": "text"
      },
      "source": [
        "## Environment\n",
        "\n",
        "The four rooms environment used at the paper, is usefull to show how the options are found and how they can use the bottleneck states to help the agent find the goal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxyjm5id9hlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # https://github.com/jeanharb/option_critic/tree/master/fourrooms\n",
        "\n",
        "class Fourrooms:\n",
        "    def __init__(self):\n",
        "        layout = \"\"\"\\\n",
        "wwwwwwwwwwwww\n",
        "w     w     w\n",
        "w     w     w\n",
        "w           w\n",
        "w     w     w\n",
        "w     w     w\n",
        "ww wwww     w\n",
        "w     www www\n",
        "w     w     w\n",
        "w     w     w\n",
        "w           w\n",
        "w     w     w\n",
        "wwwwwwwwwwwww\n",
        "\"\"\"\n",
        "        self.occupancy = np.array([list(map(lambda c: 1 if c=='w' else 0, line)) for line in layout.splitlines()])\n",
        "\n",
        "        # From any state the agent can perform one of four actions, up, down, left or right\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.observation_space = spaces.Discrete(np.sum(self.occupancy == 0))\n",
        "\n",
        "        self.directions = [np.array((-1,0)), np.array((1,0)), np.array((0,-1)), np.array((0,1))]\n",
        "        self.rng = np.random.RandomState(1234)\n",
        "\n",
        "        self.tostate = {}\n",
        "        statenum = 0\n",
        "        for i in range(13):\n",
        "            for j in range(13):\n",
        "                if self.occupancy[i, j] == 0:\n",
        "                    self.tostate[(i,j)] = statenum\n",
        "                    statenum += 1\n",
        "        self.tocell = {v:k for k,v in self.tostate.items()}\n",
        "\n",
        "        self.goal = 62\n",
        "        self.init = 0\n",
        "\n",
        "    def empty_around(self, cell):\n",
        "        avail = []\n",
        "        for action in range(self.action_space.n):\n",
        "            nextcell = tuple(cell + self.directions[action])\n",
        "            if not self.occupancy[nextcell]:\n",
        "                avail.append(nextcell)\n",
        "        return avail\n",
        "      \n",
        "    def render_values(self, states):\n",
        "      current_grid = np.array(self.occupancy)\n",
        "      pos = 0\n",
        "      for i in range(len(current_grid)):\n",
        "        for j in range(len(current_grid[0])):\n",
        "          val = current_grid[i, j]\n",
        "          if val != 1:\n",
        "            if pos in states.keys():\n",
        "              current_grid[i, j] = states[pos]\n",
        "            pos += 1\n",
        "          else:\n",
        "            current_grid[i, j] = -10\n",
        "      return current_grid\n",
        "\n",
        "          \n",
        "    def render_pos(self):\n",
        "      current_grid = np.array(self.occupancy)\n",
        "      pos = 0\n",
        "      for i in range(len(current_grid)):\n",
        "        for j in range(len(current_grid[0])):\n",
        "          val = current_grid[i, j]\n",
        "          if val != 1:\n",
        "            current_grid[i, j] = pos\n",
        "            pos += 1\n",
        "          else:\n",
        "            current_grid[i, j] = 0\n",
        "      return current_grid\n",
        "\n",
        "    def reset(self):\n",
        "        #state = self.rng.choice(self.init_states)\n",
        "        state = self.init\n",
        "        self.currentcell = self.tocell[state]\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        The agent can perform one of four actions,\n",
        "        up, down, left or right, which have a stochastic effect. With probability 2/3, the actions\n",
        "        cause the agent to move one cell in the corresponding direction, and with probability 1/3,\n",
        "        the agent moves instead in one of the other three directions, each with 1/9 probability. In\n",
        "        either case, if the movement would take the agent into a wall then the agent remains in the\n",
        "        same cell.\n",
        "        We consider a case in which rewards are zero on all state transitions.\n",
        "        \"\"\"\n",
        "        nextcell = tuple(self.currentcell + self.directions[action])\n",
        "        if not self.occupancy[nextcell]:\n",
        "            self.currentcell = nextcell\n",
        "            if self.rng.uniform() < 1/3.:\n",
        "                empty_cells = self.empty_around(self.currentcell)\n",
        "                self.currentcell = empty_cells[self.rng.randint(len(empty_cells))]\n",
        "\n",
        "        state = self.tostate[self.currentcell]\n",
        "        done = state == self.goal\n",
        "        return state, float(done), done, None\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADzN88CK96dP",
        "colab_type": "text"
      },
      "source": [
        "## Q Learning Agent\n",
        "\n",
        "$$\n",
        "Q(s_{t},a_{t})=Q(s_{t},a_{t})+\\alpha*(r+\\gamma*max_{a}Q(s_{t+1},a)-Q(s_{t}, a_{t}))\n",
        "$$\n",
        "\n",
        "I used Q-Learning to find the policy when finding the Options but the paper doesn't refer any method in particular. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmvlbjfl9qQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QLearning:\n",
        "  def __init__(self, obs_size, action_size):\n",
        "    self.epsilon = 0.4\n",
        "    self.gamma = 0.9\n",
        "    self.alpha = 0.1\n",
        "\n",
        "    self.obs_size = obs_size\n",
        "    self.action_size = action_size\n",
        "    self.q_table = np.zeros((obs_size, action_size))\n",
        "\n",
        "  def choose_action(self, s):\n",
        "    if random.random() < self.epsilon:\n",
        "      return int(random.random()*self.action_size)\n",
        "    else:\n",
        "      return np.random.choice(np.flatnonzero(self.q_table[s] == self.q_table[s].max()))\n",
        "\n",
        "  def update(self, s, a, r, s_, done):\n",
        "    if s == s_:\n",
        "      td = r\n",
        "    td = r + self.gamma * self.q_table[s_,np.argmax(self.q_table[s_])] - self.q_table[s,a]\n",
        "    self.q_table[s,a] = self.q_table[s,a] + self.alpha * td\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYYN5Y2kFHO8",
        "colab_type": "text"
      },
      "source": [
        "## Options\n",
        "\n",
        "[Options](https://www.sciencedirect.com/science/article/pii/S0004370299000521) (Precup, 2000; Sutton, Precup & Singh, 1999)\n",
        "\n",
        "An Option consists of three components $<I,\\pi,\\beta>$: $I$ is the input set and the Option is only available if $s\\in I$, $\\pi$ is the policy where $\\pi: S\\times A\\mapsto[0,1]$ and finally $\\beta$ is the termination condition. \n",
        "\n",
        "\"Primitive actions can be viewed as a special case of options.\"\n",
        "\n",
        "### Updates\n",
        "\n",
        "$$\n",
        "Q(s,o)\\leftarrow Q(s,o)+\\alpha [r+\\gamma^{k}max_{a\\in O}Q(s',a)-Q(s,o)]\n",
        "$$\n",
        "\n",
        "### Option\n",
        "\n",
        "* $\\beta$: The Option finishes when reaches it's own target, which is defined during the \"find options\" phase \n",
        "* $\\pi$: I use Q-Learning to learn the policy\n",
        "* $I$: The set is created during the \"find options\" phase \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nAgID70jEJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Options:\n",
        "  def __init__(self, options, obs_size, action_size):\n",
        "    self.obs_size = obs_size\n",
        "    self.action_size = action_size\n",
        "    self.options = options\n",
        "    self.n_options = len(options)\n",
        "    self.curr_option = -1\n",
        "    self.q_table = np.zeros((obs_size, self.n_options))\n",
        "    self.option_changed = False\n",
        "    self.k = 0\n",
        "\n",
        "    self.epsilon = 0.2\n",
        "    self.gamma = 0.9\n",
        "    self.alpha = 0.9\n",
        "\n",
        "  def _softmax(self, values):\n",
        "    exponentials = np.exp(values)\n",
        "    exp_sum = sum(exponentials)\n",
        "    return exponentials / exp_sum\n",
        "\n",
        "  def choose_action(self, s):\n",
        "    if s == self.options[self.curr_option].target or self.curr_option == -1:\n",
        "      dist = self._softmax([1 if s in option.initiation_set else 0 for option in self.options])\n",
        "      self.curr_option = np.random.choice([i for i in range(self.n_options)], p=dist)\n",
        "      self.option_changed = True\n",
        "      self.k = 0\n",
        "    return self.options[self.curr_option].choose_action(s)\n",
        "\n",
        "  def update(self, s, a, r, s_, done):\n",
        "    self.options[self.curr_option].update(s, a, r, s_, done)\n",
        "    self.k += 1\n",
        "\n",
        "    if self.option_changed:\n",
        "      max_a = self.options[self.curr_option].get_max_state(s_)\n",
        "      td = r + np.power(self.gamma, self.k) * max_a - self.q_table[s,self.curr_option]\n",
        "      self.q_table[s,self.curr_option] = self.q_table[s,self.curr_option] + self.alpha * td\n",
        "      option_changed = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhRnPujSfWyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Option:\n",
        "  def __init__(self, initiation_set, target, obs_size, action_size):\n",
        "    self.obs_size = obs_size\n",
        "    self.action_size = action_size\n",
        "    self.initiation_set = initiation_set\n",
        "    self.target = target\n",
        "    self.q_table = np.zeros((obs_size, action_size))\n",
        "\n",
        "    self.epsilon = 0.2\n",
        "    self.gamma = 0.9\n",
        "    self.alpha = 0.9\n",
        "\n",
        "  def choose_action(self, s):\n",
        "    if random.random() < self.epsilon:\n",
        "      return int(random.random()*self.action_size)\n",
        "    else:\n",
        "      return np.random.choice(np.flatnonzero(self.q_table[s] == self.q_table[s].max()))\n",
        "\n",
        "  def get_max_state(self, s):\n",
        "    return self.q_table[s, np.argmax(self.q_table[s])]\n",
        "\n",
        "  def update(self, s, a, r, s_, done):\n",
        "    td = r + self.gamma * self.q_table[s_,np.argmax(self.q_table[s_])] - self.q_table[s,a]\n",
        "    self.q_table[s,a] = self.q_table[s,a] + self.alpha * td     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2_dwYUM93If",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "\n",
        "### Find Options\n",
        "\n",
        "1. Select at random a number of start states S and target states T that will be used to\n",
        "generate random tasks for the agent.\n",
        "2. For each pair $\\langle S,T\\rangle$\n",
        "\n",
        "  (a) Perform $N_{train}$ episodes of Q-learning, to learn a policy for going from S to T\n",
        "  \n",
        "  (b) Perform $N_{test}$ episodes using the greedy policy learned. For all states s, count the total number of times $n(s)$ that each state is visited during these trajectories.\n",
        "\n",
        "3. Repeat until the desired number of options is reached:\n",
        "  \n",
        "  (a) Pick the state with the most visitations, $T_{max}=argmax_{s}n(s)$, as the target state for the option\n",
        "\n",
        "  (b) Compute $n(s,T_{max})$, the number of times each state s occurs on paths that go through $T_{max}$\n",
        "\n",
        "  (c) Compute $\\bar{n}(T_{max})=avg_{s}n(s,T_{max})$\n",
        "\n",
        "  (d) Select all the states s for which $n(s,T_{max})>\\bar{n}(T_{max})$ to be part of the initiation set 2 for the option.\n",
        "\n",
        "  (e) Complete the initiation set by interpolating between the selected states. The interpolation process is domain-specific\n",
        "\n",
        "4. For each option, learn its internal policy; this is achieved by giving a high reward for entering Tmax, and no rewards otherwise. The agent performs Q-learning, by performing episodes which start at random statesin 2 and end when Tmax isreached, or when the agent exists 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueZ0HruC-RjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_important_states(env, obs_size, action_size):\n",
        "  # 1. Select pairs <S,T>\n",
        "  pairs = []\n",
        "  n_pairs = 1000\n",
        "  i = 0\n",
        "  while i < n_pairs:\n",
        "    pairs.append((int(random.random()*obs_size), int(random.random()*obs_size)))\n",
        "    if pairs[0][0] != pairs[0][1]:\n",
        "      i += 1\n",
        "\n",
        "  # 2. Find most important states\n",
        "  NUM_EPISODES = 200\n",
        "  states_visits = {}\n",
        "  paths = []\n",
        "  \n",
        "  for pair in pairs:\n",
        "    q_learning_agent = QLearning(obs_size, action_size)\n",
        "    env.init = pair[0]\n",
        "    env.goal = pair[1]\n",
        "\n",
        "    # Train\n",
        "    for episode in range(NUM_EPISODES):\n",
        "      done = False\n",
        "\n",
        "      obs = env.reset()\n",
        "      total = 0\n",
        "      path = [obs]\n",
        "\n",
        "      while not done:\n",
        "        s = obs\n",
        "        action = q_learning_agent.choose_action(s)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        total += reward\n",
        "        s_ = obs\n",
        "        path.append(s_)\n",
        "        q_learning_agent.update(s, action, reward, s_, done)\n",
        "      paths.append(path)\n",
        "      \n",
        "    # Test\n",
        "    q_learning_agent.epsilon = 0\n",
        "    done = False\n",
        "    obs = env.reset()\n",
        "    while not done:\n",
        "      s = obs\n",
        "      if not s in states_visits:\n",
        "        states_visits[s] = 0\n",
        "      states_visits[s] += 1\n",
        "      action = q_learning_agent.choose_action(s)\n",
        "      obs, reward, done, _ = env.step(action)\n",
        "  return states_visits, paths\n",
        "\n",
        "def obtain_options(n_options, states_visits, paths, obs_size, action_size):\n",
        "  options = []\n",
        "\n",
        "  for i in range(n_options):\n",
        "    T_max = max(states_visits, key=states_visits.get) # most visited state (not temperature)\n",
        "    states_visits[T_max] = 0\n",
        "    states_occurrences = {}\n",
        "\n",
        "    # (b) Computer n_s\n",
        "    for path in paths:\n",
        "      if not T_max in path:\n",
        "        continue\n",
        "      \n",
        "      for state in path:\n",
        "        if state == T_max:\n",
        "          continue\n",
        "\n",
        "        if not state in states_occurrences:\n",
        "          states_occurrences[state] = 0\n",
        "        states_occurrences[state] += 1\n",
        "    \n",
        "    # (c) Avg\n",
        "    val_sum = sum(states_occurrences.values())\n",
        "    avg = sum([n/val_sum for n in states_occurrences.values()])\n",
        "\n",
        "    # (d) Select all the states s for which n_s > avg\n",
        "    selected_states = []\n",
        "    for state in states_occurrences.keys():\n",
        "      occurrences = states_occurrences[state]\n",
        "      if occurrences > avg:\n",
        "        selected_states.append(state)\n",
        "    options.append(Option(selected_states, T_max, obs_size, action_size))\n",
        "    \n",
        "  return options\n",
        "\n",
        "def find_options(n_options=8):\n",
        "  env = Fourrooms()\n",
        "  obs_size = env.observation_space.n\n",
        "  action_size = env.action_space.n\n",
        "\n",
        "  states_visits, paths = find_important_states(env, obs_size, action_size)\n",
        "\n",
        "  plt.matshow(env.render_values(states_visits))\n",
        "  plt.title(\"States visits\", pad=10.0)\n",
        "  plt.show()\n",
        "\n",
        "  # 3. Obtain Options\n",
        "  return obtain_options(n_options, states_visits, paths, obs_size, action_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gEhOWvU-Tis",
        "colab_type": "text"
      },
      "source": [
        "### Train Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpmfenGk-Fm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(options):\n",
        "  env = Fourrooms()\n",
        "  obs_size = env.observation_space.n\n",
        "  action_size = env.action_space.n\n",
        "\n",
        "  # Options\n",
        "  options_q_learning = Options(options, obs_size, action_size)\n",
        "    \n",
        "  env.init = 1\n",
        "  env.goal = 63\n",
        "  n_steps_arr = []\n",
        "  # Train\n",
        "  NUM_EPISODES = 5000\n",
        "  GOAL_CHANGES = 2\n",
        "  BATCH_SIZE = 20\n",
        "\n",
        "  path = []\n",
        "  batch_n = 0\n",
        "  batch_avg = 0\n",
        "  n_steps_arr = np.empty(0, dtype=int)\n",
        "\n",
        "  for episode in range(NUM_EPISODES):\n",
        "    done = False\n",
        "    obs = env.reset()\n",
        "    n_steps = 0\n",
        "    total = 0\n",
        "    while not done:\n",
        "      s = obs\n",
        "      action = options_q_learning.choose_action(s)\n",
        "      obs, reward, done, _ = env.step(action)\n",
        "      total += reward\n",
        "      s_ = obs\n",
        "      path.append(s_)\n",
        "      options_q_learning.update(s, action, reward, s_, done)\n",
        "      n_steps += 1\n",
        "\n",
        "    batch_n += 1\n",
        "    batch_avg += n_steps/BATCH_SIZE\n",
        "\n",
        "    if episode % (NUM_EPISODES/GOAL_CHANGES) == 0:\n",
        "      env.init = int(random.random()*obs_size) \n",
        "      env.goal = int(random.random()*obs_size)\n",
        "\n",
        "    if batch_n % BATCH_SIZE == 0:\n",
        "      n_steps_arr = np.append(n_steps_arr, batch_avg)\n",
        "      batch_avg = 0\n",
        "\n",
        "  \n",
        "  x = np.arange(1,(NUM_EPISODES/BATCH_SIZE)+1)\n",
        "  plt.plot(x, n_steps_arr)\n",
        "  plt.title(\"Training steps (start and goal changes in the middle)\")\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii6UeoSA-rLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "c8c0e94d-a51b-495f-883d-49db120dbdfc"
      },
      "source": [
        "options = find_options()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jk5PzRFD-nv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "5f7594cb-edc3-4bca-9296-502e6f71ffc4"
      },
      "source": [
        "train(options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqzOM41CWfVX",
        "colab_type": "text"
      },
      "source": [
        "## Final Thoughts\n",
        "\n",
        "I like this method more than the Feudal RL. The Option idea is really interesting and the relationship between options and actions makes them very intuitive. However, the introduction of the option components ($\\pi, \\beta, I$) adds some complexity that we didn't have with only primitive actions. Another problem with this implementation in specific is that we need to find the Options before learning the policy over options. Fortunately, [The Option-Critic Architecture](https://arxiv.org/abs/1609.05140) proposes a solution that learns both the internal policies and the termination conditions of options, in tandem with the policy over options.\n",
        "\n",
        "When comparing Feudal to Options some ideas emerge. The way I see is that in Feudal each state at any level is an Option (trivial at Level-0), so basically Feudal is a stack of groups of policies over options, but the Options are predefined and not learned. While the Options Framework only has one layer of options, they are learned which can be an advantage. Obviously, this is a very (very) rough comparison. But I made this comparison because, in my opinion, it would be interesting to explore a new Options method that not only learns the options in parallel but also can introduce a new layer of options that controls the policies over options below. An example is how we behave in our lives, we have big long-term goals, mid-term goals, short-term goals and finally, we have daily goals. And all these goals influence in some way all the decisions we make, we set mid-term goals based on long-terms, short-term goals based on mid-term goals and so on. \n",
        "\n"
      ]
    }
  ]
}